{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using multi-agent RL with Ray RLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to implement a multi-agent RL based on Proximal Policy Optimization (PPO) algorithm using Ray RLlib. We are going to utilize the custom environment RobotsMeeting created in [lesson 3 nb 1](./1-exploring_multi_agent_environment.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium.spaces as spaces\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.tune.registry import register_env\n",
    "import numpy as np\n",
    "from ray import air, tune\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from typing import Dict\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below implements the environment for the cooperative navigation problem explained in the previous notebook [lesson 3 nb 1](./1-exploring_multi_agent_environment.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotsMeeting(\n",
    "    MultiAgentEnv\n",
    "):  # We have to inherit from MultiAgentEnv from Ray RLlib similarly to Gymnasium API\n",
    "    def __init__(\n",
    "        self,\n",
    "        scenario_size: int = 10,\n",
    "        render: bool = False,\n",
    "    ):\n",
    "        self.scenario_size = scenario_size  # scenario_size x scenario_size grid\n",
    "        self.scenario = np.zeros((self.scenario_size, self.scenario_size))\n",
    "        self.action_space = spaces.Dict(\n",
    "            {\n",
    "                \"robot_1\": spaces.Discrete(4),  # 0: up, 1: down, 2: left, 3: right\n",
    "                \"robot_2\": spaces.Discrete(4),\n",
    "            }\n",
    "        )\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"robot_1\": spaces.Discrete(\n",
    "                    self.scenario_size * 2 - 2\n",
    "                ),  # The maximum distance between two points in a grid is 2 * scenario_size - 2\n",
    "                \"robot_2\": spaces.Discrete(self.scenario_size * 2 - 2),\n",
    "            }\n",
    "        )\n",
    "        self.robots = {\n",
    "            \"robot_1\": {\n",
    "                \"number\": 1,\n",
    "                \"pos\": [0, 0],\n",
    "            },\n",
    "            \"robot_2\": {\n",
    "                \"number\": 2,\n",
    "                \"pos\": [self.scenario_size - 1, self.scenario_size - 1],\n",
    "            },\n",
    "        }\n",
    "        self.scenario[0, 0] = self.robots[\"robot_1\"][\"number\"]\n",
    "        self.scenario[self.scenario_size - 1, self.scenario_size - 1] = self.robots[\n",
    "            \"robot_2\"\n",
    "        ][\"number\"]\n",
    "        if render:\n",
    "            plt.figure()\n",
    "            plt.show()\n",
    "            self.render()\n",
    "\n",
    "    def reset(self):\n",
    "        # Reseting scenario and returning robots to initial positions\n",
    "        self.scenario = np.zeros((self.scenario_size, self.scenario_size))\n",
    "        self.scenario[0, 0] = self.robots[\"robot_1\"][\"number\"]\n",
    "        self.scenario[self.scenario_size - 1, self.scenario_size - 1] = self.robots[\n",
    "            \"robot_2\"\n",
    "        ][\"number\"]\n",
    "        obs = {\n",
    "            \"robot_1\": self.scenario_size * 2 - 2,\n",
    "            \"robot_2\": self.scenario_size * 2 - 2,\n",
    "        }\n",
    "        info = {}\n",
    "        return (obs, info)\n",
    "\n",
    "    def step(self, action_dict):\n",
    "        for agent, action in action_dict.items():\n",
    "            if action == 0:  # Up\n",
    "                if self.robots[agent][\"pos\"][0] == 0:\n",
    "                    continue\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0], self.robots[agent][\"pos\"][1]\n",
    "                ] = 0\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0] - 1, self.robots[agent][\"pos\"][1]\n",
    "                ] = self.robots[agent][\"number\"]\n",
    "                self.robots[agent][\"pos\"][0] -= 1\n",
    "            elif action == 1:  # Down\n",
    "                if self.robots[agent][\"pos\"][0] == self.scenario_size - 1:\n",
    "                    continue\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0], self.robots[agent][\"pos\"][1]\n",
    "                ] = 0\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0] + 1, self.robots[agent][\"pos\"][1]\n",
    "                ] = self.robots[agent][\"number\"]\n",
    "                self.robots[agent][\"pos\"][0] += 1\n",
    "            elif action == 2:  # Left\n",
    "                if self.robots[agent][\"pos\"][1] == 0:\n",
    "                    continue\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0], self.robots[agent][\"pos\"][1]\n",
    "                ] = 0\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0], self.robots[agent][\"pos\"][1] - 1\n",
    "                ] = self.robots[agent][\"number\"]\n",
    "                self.robots[agent][\"pos\"][1] -= 1\n",
    "            elif action == 3:  # Right\n",
    "                if self.robots[agent][\"pos\"][1] == self.scenario_size - 1:\n",
    "                    continue\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0], self.robots[agent][\"pos\"][1]\n",
    "                ] = 0\n",
    "                self.scenario[\n",
    "                    self.robots[agent][\"pos\"][0], self.robots[agent][\"pos\"][1] + 1\n",
    "                ] = self.robots[agent][\"number\"]\n",
    "                self.robots[agent][\"pos\"][1] += 1\n",
    "            else:\n",
    "                raise ValueError(\"Invalid action\")\n",
    "\n",
    "        distance = np.abs(  # Calculate the distance between two robots\n",
    "            self.robots[\"robot_1\"][\"pos\"][0] - self.robots[\"robot_2\"][\"pos\"][0]\n",
    "        ) + np.abs(self.robots[\"robot_1\"][\"pos\"][1] - self.robots[\"robot_2\"][\"pos\"][1])\n",
    "        obs = {\n",
    "            \"robot_1\": distance,\n",
    "            \"robot_2\": distance,\n",
    "        }\n",
    "        reward_value = (\n",
    "            0 if np.isclose(distance, 0) else -1\n",
    "        )  # Reward is 0 if the robots meet, -1 otherwise\n",
    "        done = (\n",
    "            True if reward_value == 0 else False\n",
    "        )  # Terminate the episode if the robots meet\n",
    "        reward = {\"robot_1\": reward_value, \"robot_2\": reward_value}\n",
    "        terminated = {\"player_1\": done, \"player_2\": done}\n",
    "        truncated = {\"player_1\": done, \"player_2\": done}\n",
    "        terminated[\"__all__\"], truncated[\"__all__\"] = done, done\n",
    "        info = {}\n",
    "        return (obs, reward, terminated, truncated, info)\n",
    "\n",
    "    def render(self):\n",
    "        clear_output(wait=True)\n",
    "        plt.imshow(self.scenario)\n",
    "        plt.show()\n",
    "\n",
    "    def close(self):\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registering our custom environment in the Ray RLlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config):\n",
    "    env = RobotsMeeting(scenario_size=10)\n",
    "    return env\n",
    "\n",
    "\n",
    "register_env(\"robots_meeting\", lambda config: env_creator(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the multi-agent RL using PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_mapping_fn_shared(agent_id, episode=None, worker=None, **kwargs):\n",
    "    agent_idx = int(agent_id.partition(\"_\")[2])\n",
    "\n",
    "    return \"robot_1\" if agent_idx == 1 else \"robot_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_policies() -> Dict[str, PolicySpec]:\n",
    "    policies = {\n",
    "        \"robot_1\": PolicySpec(),\n",
    "        \"robot_2\": PolicySpec(),\n",
    "    }\n",
    "\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_config = (\n",
    "    PPOConfig()\n",
    "    .environment(\n",
    "        env=\"robots_meeting\",\n",
    "    )\n",
    "    .multi_agent(\n",
    "        policies=generate_policies(),\n",
    "        policy_mapping_fn=policy_mapping_fn_shared,\n",
    "        count_steps_by=\"env_steps\",\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 02:25:20,541\tINFO worker.py:1783 -- Started a local Ray instance.\n",
      "2024-12-06 02:25:21,105\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2024-12-06 02:25:21,107\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-06 02:25:29</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:08.84        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.8/23.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/16 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_robots_meeting_57723_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-12-06_02-25-19_807012_621363/artifacts/2024-12-06_02-25-21/ray_ppo/driver_artifacts/PPO_robots_meeting_57723_00000_0_2024-12-06_02-25-21/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>status  </th><th>loc                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_robots_meeting_57723_00000</td><td>ERROR   </td><td>200.239.93.233:623065</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 02:25:29,978\tERROR tune_controller.py:1331 -- Trial task failed for trial PPO_robots_meeting_57723_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/_private/worker.py\", line 2661, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::PPO.train()\u001b[39m (pid=623065, ip=200.239.93.233, actor_id=09b450b673ac5ee852c8f37e01000000, repr=PPO)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 328, in train\n",
      "    result = self.step()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 951, in step\n",
      "    train_results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 3600, in _run_one_training_iteration\n",
      "    training_step_results = self.training_step()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 434, in training_step\n",
      "    return self._training_step_old_and_hybrid_api_stacks()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 547, in _training_step_old_and_hybrid_api_stacks\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
      "    sampled_data = worker_set.foreach_worker(\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/env_runner_group.py\", line 900, in foreach_worker\n",
      "    _handle_remote_call_result_errors(\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/env_runner_group.py\", line 1254, in _handle_remote_call_result_errors\n",
      "    raise r.get()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=623137, ip=200.239.93.233, actor_id=f095575c148e45426b52388301000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fd79a5c2d40>)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\", line 192, in apply\n",
      "    raise e\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\", line 181, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 102, in <lambda>\n",
      "    (lambda w: w.sample(**random_action_kwargs))\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 678, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 91, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 273, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 348, in run\n",
      "    outputs = self.step()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 367, in step\n",
      "    ) = self._base_env.poll()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 634, in poll\n",
      "    ) = env_state.poll()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 837, in poll\n",
      "    self.reset()\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 921, in reset\n",
      "    raise e\n",
      "  File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 915, in reset\n",
      "    obs_and_infos = self.env.reset(seed=seed, options=options)\n",
      "TypeError: RobotsMeeting.reset() got an unexpected keyword argument 'seed'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_robots_meeting_57723_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 02:25:29,986\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/lasse/ray_minicourse/lesson_3/ray_results/nb_3/ray_ppo' in 0.0033s.\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m 2024-12-06 02:25:29,974\tERROR actor_manager.py:523 -- Ray error, taking actor 1 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=623137, ip=200.239.93.233, actor_id=f095575c148e45426b52388301000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fd79a5c2d40>)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\", line 192, in apply\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     raise e\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\", line 181, in apply\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     return func(self, *args, **kwargs)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 102, in <lambda>\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     (lambda w: w.sample(**random_action_kwargs))\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 678, in sample\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 91, in next\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 273, in get_data\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     item = next(self._env_runner)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 348, in run\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     outputs = self.step()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 367, in step\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     ) = self._base_env.poll()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 634, in poll\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     ) = env_state.poll()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 837, in poll\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     self.reset()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 921, in reset\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     raise e\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 915, in reset\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     obs_and_infos = self.env.reset(seed=seed, options=options)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m TypeError: RobotsMeeting.reset() got an unexpected keyword argument 'seed'\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m 2024-12-06 02:25:29,974\tERROR actor_manager.py:523 -- Ray error, taking actor 2 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=623138, ip=200.239.93.233, actor_id=35c077c92f2f29eced9f624f01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f30e3a2ad70>)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\", line 192, in apply\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     raise e\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\", line 181, in apply\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     return func(self, *args, **kwargs)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 102, in <lambda>\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     (lambda w: w.sample(**random_action_kwargs))\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 678, in sample\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 91, in next\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 273, in get_data\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     item = next(self._env_runner)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 348, in run\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     outputs = self.step()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 367, in step\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     ) = self._base_env.poll()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 634, in poll\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     ) = env_state.poll()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 837, in poll\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     self.reset()\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 921, in reset\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     raise e\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m   File \"/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 915, in reset\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m     obs_and_infos = self.env.reset(seed=seed, options=options)\n",
      "\u001b[36m(PPO pid=623065)\u001b[0m TypeError: RobotsMeeting.reset() got an unexpected keyword argument 'seed'\n",
      "2024-12-06 02:25:30,672\tERROR tune.py:1037 -- Trials did not complete: [PPO_robots_meeting_57723_00000]\n",
      "2024-12-06 02:25:30,672\tINFO tune.py:1041 -- Total run time: 9.57 seconds (8.84 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultGrid<[\n",
      "  Result(\n",
      "    error='RayTaskError(TypeError)',\n",
      "    metrics={},\n",
      "    path='/home/lasse/ray_minicourse/lesson_3/ray_results/nb_3/ray_ppo/PPO_robots_meeting_57723_00000_0_2024-12-06_02-25-21',\n",
      "    filesystem='local',\n",
      "    checkpoint=None\n",
      "  )\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "stop = {\n",
    "    \"training_iterations\": 100,\n",
    "}\n",
    "checkpoint_frequency = 0\n",
    "store_results_path = str(Path(\"./ray_results/\").resolve()) + \"/nb_3/\"\n",
    "agent_name = \"ray_ppo\"\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space=algo_config.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        storage_path=store_results_path,\n",
    "        name=agent_name,\n",
    "        stop=stop,\n",
    "        verbose=2,\n",
    "        checkpoint_config=air.CheckpointConfig(\n",
    "            checkpoint_frequency=checkpoint_frequency,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray_minicourse-PTDOXG61",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
