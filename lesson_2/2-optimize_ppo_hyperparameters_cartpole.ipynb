{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing PPO RL agent as trainable and optimizing the hyperparameters in the Cartpole environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the search space for the PPO hyperparameters we want to tune/optimize. So, we can check the [PPO config training](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#ray.rllib.algorithms.ppo.ppo.PPOConfig) in the Ray RLlib page to verify the specific PPO hyperparameters, and also the [general RL algorithm hyperparameters](https://docs.ray.io/en/latest/rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.training.html#ray-rllib-algorithms-algorithm-config-algorithmconfig-training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we will try to optimize the learning rate `lr` and the discount factor `gamma` hyperparameters. We can check the common values assumed for these variables using the SB3 Zoo [here](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/rl_zoo3/hyperparams_opt.py). These values were defined based on community experience using the software and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ray import air, tune\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.algorithm import Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1),\n",
    "    \"gamma\": tune.choice(\n",
    "        [\n",
    "            0.5,\n",
    "            0.6,\n",
    "            0.7,\n",
    "            0.8,\n",
    "            0.9,\n",
    "            0.95,\n",
    "            0.98,\n",
    "            0.99,\n",
    "            0.995,\n",
    "            0.999,\n",
    "            0.9999,\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the `loguniform` and the `choice` search space [here](https://docs.ray.io/en/latest/tune/api/search_space.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ray Tune, there is a Search Space algorithm responsible for selecting the hyperparameters to be used in a trial. In this example, we are using a Random Search algorithm that randomly selects samples from the hyperparameters in the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_algo = tune.search.basic_variant.BasicVariantGenerator()  # Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ray Tune, there is also a Trial Scheduler algorithm responsible for early terminate bad trials, pause trials, clone trials, and alter hyperparameters of a running trial. In this example, we are considering a simple scheduler that only allocates the trials in the FIFO order without pausing, terminating or altering hyperparameters of a running trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_algo = tune.schedulers.FIFOScheduler()  # FIFO trial scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the search and scheduler algorithms are defined, we can define our Tune configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_trials = 2\n",
    "tune_config = tune.TuneConfig(\n",
    "    metric=\"env_runners/episode_reward_mean\",  # That's the metric we want to maximize/minimize\n",
    "    mode=\"max\",  # Here we indicate we want to maximize the metric env_runners/episode_reward_mean\n",
    "    scheduler=scheduler_algo,\n",
    "    search_alg=search_algo,\n",
    "    num_samples=number_trials,  # Number of trials to run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's initialize our Tuner and train the PPO RL agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 02:50:09,520\tINFO worker.py:1783 -- Started a local Ray instance.\n",
      "2024-11-30 02:50:10,043\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2024-11-30 02:50:10,045\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/lasse/.local/share/virtualenvs/ray_minicourse-PTDOXG61/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-30 02:51:52</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:42.19        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.5/23.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/16 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_\n",
       "sample_reqs</th><th style=\"text-align: right;\">  num_remote_worker_re\n",
       "starts</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v1_cfa8c_00000</td><td>TERMINATED</td><td>200.239.93.233:515764</td><td style=\"text-align: right;\">  0.995</td><td style=\"text-align: right;\">1.39853e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         93.8896</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td>PPO_CartPole-v1_cfa8c_00001</td><td>TERMINATED</td><td>200.239.93.233:515765</td><td style=\"text-align: right;\">  0.5  </td><td style=\"text-align: right;\">0.0029496  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         94.2231</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=515765)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(PPO pid=515765)\u001b[0m 2024-11-30 02:50:19,838\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                            </th><th>custom_metrics  </th><th>env_runners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </th><th>episode_media  </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_sample_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                                                    </th><th>timers                                                                                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v1_cfa8c_00000</td><td style=\"text-align: right;\">                  40000</td><td>{&#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 40000, &#x27;num_agent_steps_trained&#x27;: 40000}</td><td>{}              </td><td>{&#x27;episode_reward_max&#x27;: 500.0, &#x27;episode_reward_min&#x27;: 30.0, &#x27;episode_reward_mean&#x27;: np.float64(278.86), &#x27;episode_len_mean&#x27;: np.float64(278.86), &#x27;episode_media&#x27;: {}, &#x27;episodes_timesteps_total&#x27;: 27886, &#x27;policy_reward_min&#x27;: {&#x27;default_policy&#x27;: np.float64(30.0)}, &#x27;policy_reward_max&#x27;: {&#x27;default_policy&#x27;: np.float64(500.0)}, &#x27;policy_reward_mean&#x27;: {&#x27;default_policy&#x27;: np.float64(278.86)}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [79.0, 59.0, 30.0, 99.0, 226.0, 171.0, 131.0, 256.0, 184.0, 77.0, 152.0, 180.0, 94.0, 136.0, 54.0, 227.0, 232.0, 167.0, 85.0, 153.0, 195.0, 162.0, 167.0, 120.0, 172.0, 295.0, 154.0, 203.0, 324.0, 91.0, 250.0, 57.0, 64.0, 103.0, 286.0, 275.0, 233.0, 166.0, 139.0, 267.0, 340.0, 178.0, 237.0, 99.0, 357.0, 206.0, 66.0, 383.0, 389.0, 288.0, 261.0, 388.0, 322.0, 202.0, 332.0, 310.0, 188.0, 348.0, 221.0, 86.0, 99.0, 291.0, 302.0, 500.0, 369.0, 492.0, 367.0, 249.0, 363.0, 279.0, 203.0, 324.0, 122.0, 500.0, 500.0, 324.0, 296.0, 460.0, 500.0, 500.0, 359.0, 418.0, 348.0, 294.0, 500.0, 468.0, 500.0, 412.0, 500.0, 500.0, 500.0, 500.0, 500.0, 427.0, 500.0, 500.0, 500.0, 500.0, 404.0, 500.0], &#x27;episode_lengths&#x27;: [79, 59, 30, 99, 226, 171, 131, 256, 184, 77, 152, 180, 94, 136, 54, 227, 232, 167, 85, 153, 195, 162, 167, 120, 172, 295, 154, 203, 324, 91, 250, 57, 64, 103, 286, 275, 233, 166, 139, 267, 340, 178, 237, 99, 357, 206, 66, 383, 389, 288, 261, 388, 322, 202, 332, 310, 188, 348, 221, 86, 99, 291, 302, 500, 369, 492, 367, 249, 363, 279, 203, 324, 122, 500, 500, 324, 296, 460, 500, 500, 359, 418, 348, 294, 500, 468, 500, 412, 500, 500, 500, 500, 500, 427, 500, 500, 500, 500, 404, 500], &#x27;policy_default_policy_reward&#x27;: [79.0, 59.0, 30.0, 99.0, 226.0, 171.0, 131.0, 256.0, 184.0, 77.0, 152.0, 180.0, 94.0, 136.0, 54.0, 227.0, 232.0, 167.0, 85.0, 153.0, 195.0, 162.0, 167.0, 120.0, 172.0, 295.0, 154.0, 203.0, 324.0, 91.0, 250.0, 57.0, 64.0, 103.0, 286.0, 275.0, 233.0, 166.0, 139.0, 267.0, 340.0, 178.0, 237.0, 99.0, 357.0, 206.0, 66.0, 383.0, 389.0, 288.0, 261.0, 388.0, 322.0, 202.0, 332.0, 310.0, 188.0, 348.0, 221.0, 86.0, 99.0, 291.0, 302.0, 500.0, 369.0, 492.0, 367.0, 249.0, 363.0, 279.0, 203.0, 324.0, 122.0, 500.0, 500.0, 324.0, 296.0, 460.0, 500.0, 500.0, 359.0, 418.0, 348.0, 294.0, 500.0, 468.0, 500.0, 412.0, 500.0, 500.0, 500.0, 500.0, 500.0, 427.0, 500.0, 500.0, 500.0, 500.0, 404.0, 500.0]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: np.float64(0.19439578188943432), &#x27;mean_inference_ms&#x27;: np.float64(0.6707228199427331), &#x27;mean_action_processing_ms&#x27;: np.float64(0.07895767599599109), &#x27;mean_env_wait_ms&#x27;: np.float64(0.04029074512553687), &#x27;mean_env_render_ms&#x27;: np.float64(0.0)}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: np.float64(0.0043277740478515625), &#x27;StateBufferConnector_ms&#x27;: np.float64(0.003129243850708008), &#x27;ViewRequirementAgentConnector_ms&#x27;: np.float64(0.08161735534667969)}, &#x27;num_episodes&#x27;: 8, &#x27;episode_return_max&#x27;: 500.0, &#x27;episode_return_min&#x27;: 30.0, &#x27;episode_return_mean&#x27;: np.float64(278.86), &#x27;episodes_this_iter&#x27;: 8}</td><td>{}             </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: np.float64(0.0), &#x27;grad_gnorm&#x27;: np.float32(0.36715484), &#x27;cur_kl_coeff&#x27;: np.float64(0.01875), &#x27;cur_lr&#x27;: np.float64(1.3985265446433982e-05), &#x27;total_loss&#x27;: np.float64(9.929167386536957), &#x27;policy_loss&#x27;: np.float64(-0.01733068605904938), &#x27;vf_loss&#x27;: np.float64(9.94645794078868), &#x27;vf_explained_var&#x27;: np.float64(-0.06159804110885948), &#x27;kl&#x27;: np.float64(0.0021413145434349998), &#x27;entropy&#x27;: np.float64(0.5399863363594137), &#x27;entropy_coeff&#x27;: np.float64(0.0)}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: np.float64(128.0), &#x27;num_grad_updates_lifetime&#x27;: np.float64(8835.5), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float64(464.5)}}, &#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 40000, &#x27;num_agent_steps_trained&#x27;: 40000}          </td><td style=\"text-align: right;\">                    40000</td><td style=\"text-align: right;\">                             40000</td><td style=\"text-align: right;\">                    40000</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                           40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   427.598</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   427.598</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(15.638461538461542), &#x27;ram_util_percent&#x27;: np.float64(27.600000000000005)}</td><td>{&#x27;training_iteration_time_ms&#x27;: 9385.326, &#x27;restore_workers_time_ms&#x27;: 0.017, &#x27;training_step_time_ms&#x27;: 9385.279, &#x27;sample_time_ms&#x27;: 2011.235, &#x27;load_time_ms&#x27;: 0.323, &#x27;load_throughput&#x27;: 12378055.187, &#x27;learn_time_ms&#x27;: 7369.253, &#x27;learn_throughput&#x27;: 542.796, &#x27;synch_weights_time_ms&#x27;: 3.983}</td></tr>\n",
       "<tr><td>PPO_CartPole-v1_cfa8c_00001</td><td style=\"text-align: right;\">                  40000</td><td>{&#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 40000, &#x27;num_agent_steps_trained&#x27;: 40000}</td><td>{}              </td><td>{&#x27;episode_reward_max&#x27;: 284.0, &#x27;episode_reward_min&#x27;: 24.0, &#x27;episode_reward_mean&#x27;: np.float64(83.7), &#x27;episode_len_mean&#x27;: np.float64(83.7), &#x27;episode_media&#x27;: {}, &#x27;episodes_timesteps_total&#x27;: 8370, &#x27;policy_reward_min&#x27;: {&#x27;default_policy&#x27;: np.float64(24.0)}, &#x27;policy_reward_max&#x27;: {&#x27;default_policy&#x27;: np.float64(284.0)}, &#x27;policy_reward_mean&#x27;: {&#x27;default_policy&#x27;: np.float64(83.7)}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [118.0, 58.0, 100.0, 53.0, 68.0, 171.0, 103.0, 99.0, 108.0, 92.0, 284.0, 91.0, 87.0, 58.0, 66.0, 77.0, 81.0, 49.0, 62.0, 93.0, 65.0, 37.0, 71.0, 104.0, 62.0, 90.0, 68.0, 86.0, 62.0, 149.0, 24.0, 57.0, 47.0, 87.0, 93.0, 47.0, 47.0, 54.0, 82.0, 59.0, 90.0, 66.0, 53.0, 92.0, 76.0, 58.0, 119.0, 85.0, 53.0, 100.0, 93.0, 60.0, 78.0, 122.0, 88.0, 55.0, 73.0, 26.0, 79.0, 60.0, 75.0, 94.0, 107.0, 36.0, 110.0, 96.0, 116.0, 124.0, 69.0, 100.0, 57.0, 56.0, 125.0, 82.0, 126.0, 146.0, 75.0, 85.0, 118.0, 77.0, 77.0, 69.0, 83.0, 103.0, 90.0, 80.0, 78.0, 88.0, 69.0, 136.0, 91.0, 65.0, 41.0, 148.0, 79.0, 77.0, 87.0, 72.0, 68.0, 60.0], &#x27;episode_lengths&#x27;: [118, 58, 100, 53, 68, 171, 103, 99, 108, 92, 284, 91, 87, 58, 66, 77, 81, 49, 62, 93, 65, 37, 71, 104, 62, 90, 68, 86, 62, 149, 24, 57, 47, 87, 93, 47, 47, 54, 82, 59, 90, 66, 53, 92, 76, 58, 119, 85, 53, 100, 93, 60, 78, 122, 88, 55, 73, 26, 79, 60, 75, 94, 107, 36, 110, 96, 116, 124, 69, 100, 57, 56, 125, 82, 126, 146, 75, 85, 118, 77, 77, 69, 83, 103, 90, 80, 78, 88, 69, 136, 91, 65, 41, 148, 79, 77, 87, 72, 68, 60], &#x27;policy_default_policy_reward&#x27;: [118.0, 58.0, 100.0, 53.0, 68.0, 171.0, 103.0, 99.0, 108.0, 92.0, 284.0, 91.0, 87.0, 58.0, 66.0, 77.0, 81.0, 49.0, 62.0, 93.0, 65.0, 37.0, 71.0, 104.0, 62.0, 90.0, 68.0, 86.0, 62.0, 149.0, 24.0, 57.0, 47.0, 87.0, 93.0, 47.0, 47.0, 54.0, 82.0, 59.0, 90.0, 66.0, 53.0, 92.0, 76.0, 58.0, 119.0, 85.0, 53.0, 100.0, 93.0, 60.0, 78.0, 122.0, 88.0, 55.0, 73.0, 26.0, 79.0, 60.0, 75.0, 94.0, 107.0, 36.0, 110.0, 96.0, 116.0, 124.0, 69.0, 100.0, 57.0, 56.0, 125.0, 82.0, 126.0, 146.0, 75.0, 85.0, 118.0, 77.0, 77.0, 69.0, 83.0, 103.0, 90.0, 80.0, 78.0, 88.0, 69.0, 136.0, 91.0, 65.0, 41.0, 148.0, 79.0, 77.0, 87.0, 72.0, 68.0, 60.0]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: np.float64(0.1992350386598566), &#x27;mean_inference_ms&#x27;: np.float64(0.6674608949034192), &#x27;mean_action_processing_ms&#x27;: np.float64(0.07855310032530356), &#x27;mean_env_wait_ms&#x27;: np.float64(0.04027246995109764), &#x27;mean_env_render_ms&#x27;: np.float64(0.0)}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: np.float64(0.004766941070556641), &#x27;StateBufferConnector_ms&#x27;: np.float64(0.003278970718383789), &#x27;ViewRequirementAgentConnector_ms&#x27;: np.float64(0.0824594497680664)}, &#x27;num_episodes&#x27;: 46, &#x27;episode_return_max&#x27;: 284.0, &#x27;episode_return_min&#x27;: 24.0, &#x27;episode_return_mean&#x27;: np.float64(83.7), &#x27;episodes_this_iter&#x27;: 46}                                                                                                                                                                                                    </td><td>{}             </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: np.float64(0.0), &#x27;grad_gnorm&#x27;: np.float32(0.36532947), &#x27;cur_kl_coeff&#x27;: np.float64(0.6750000000000002), &#x27;cur_lr&#x27;: np.float64(0.0029495964113414592), &#x27;total_loss&#x27;: np.float64(-0.01114009203619614), &#x27;policy_loss&#x27;: np.float64(-0.01957856527259273), &#x27;vf_loss&#x27;: np.float64(0.0027076304654568254), &#x27;vf_explained_var&#x27;: np.float64(0.846721371335368), &#x27;kl&#x27;: np.float64(0.00849013701074782), &#x27;entropy&#x27;: np.float64(0.5356226322151), &#x27;entropy_coeff&#x27;: np.float64(0.0)}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: np.float64(128.0), &#x27;num_grad_updates_lifetime&#x27;: np.float64(8835.5), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float64(464.5)}}, &#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 40000, &#x27;num_agent_steps_trained&#x27;: 40000}</td><td style=\"text-align: right;\">                    40000</td><td style=\"text-align: right;\">                             40000</td><td style=\"text-align: right;\">                    40000</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                           40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   421.976</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   421.976</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(15.471428571428573), &#x27;ram_util_percent&#x27;: np.float64(27.264285714285716)}</td><td>{&#x27;training_iteration_time_ms&#x27;: 9418.291, &#x27;restore_workers_time_ms&#x27;: 0.017, &#x27;training_step_time_ms&#x27;: 9418.243, &#x27;sample_time_ms&#x27;: 2024.944, &#x27;load_time_ms&#x27;: 0.342, &#x27;load_throughput&#x27;: 11695514.814, &#x27;learn_time_ms&#x27;: 7388.48, &#x27;learn_throughput&#x27;: 541.383, &#x27;synch_weights_time_ms&#x27;: 3.987} </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=515764)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/lasse/ray_minicourse/lesson_2/ray_results/nb_2/ppo_cartpole/PPO_CartPole-v1_cfa8c_00000_0_gamma=0.9950,lr=0.0000_2024-11-30_02-50-10/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=515764)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(PPO pid=515764)\u001b[0m 2024-11-30 02:50:19,875\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n",
      "2024-11-30 02:51:52,274\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/lasse/ray_minicourse/lesson_2/ray_results/nb_2/ppo_cartpole' in 0.0166s.\n",
      "2024-11-30 02:51:52,763\tINFO tune.py:1041 -- Total run time: 102.72 seconds (102.18 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultGrid<[\n",
      "  Result(\n",
      "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(0.36715484), 'cur_kl_coeff': np.float64(0.01875), 'cur_lr': np.float64(1.3985265446433982e-05), 'total_loss': np.float64(9.929167386536957), 'policy_loss': np.float64(-0.01733068605904938), 'vf_loss': np.float64(9.94645794078868), 'vf_explained_var': np.float64(-0.06159804110885948), 'kl': np.float64(0.0021413145434349998), 'entropy': np.float64(0.5399863363594137), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(128.0), 'num_grad_updates_lifetime': np.float64(8835.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(464.5)}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'env_runners': {'episode_reward_max': 500.0, 'episode_reward_min': 30.0, 'episode_reward_mean': np.float64(278.86), 'episode_len_mean': np.float64(278.86), 'episode_media': {}, 'episodes_timesteps_total': 27886, 'policy_reward_min': {'default_policy': np.float64(30.0)}, 'policy_reward_max': {'default_policy': np.float64(500.0)}, 'policy_reward_mean': {'default_policy': np.float64(278.86)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [79.0, 59.0, 30.0, 99.0, 226.0, 171.0, 131.0, 256.0, 184.0, 77.0, 152.0, 180.0, 94.0, 136.0, 54.0, 227.0, 232.0, 167.0, 85.0, 153.0, 195.0, 162.0, 167.0, 120.0, 172.0, 295.0, 154.0, 203.0, 324.0, 91.0, 250.0, 57.0, 64.0, 103.0, 286.0, 275.0, 233.0, 166.0, 139.0, 267.0, 340.0, 178.0, 237.0, 99.0, 357.0, 206.0, 66.0, 383.0, 389.0, 288.0, 261.0, 388.0, 322.0, 202.0, 332.0, 310.0, 188.0, 348.0, 221.0, 86.0, 99.0, 291.0, 302.0, 500.0, 369.0, 492.0, 367.0, 249.0, 363.0, 279.0, 203.0, 324.0, 122.0, 500.0, 500.0, 324.0, 296.0, 460.0, 500.0, 500.0, 359.0, 418.0, 348.0, 294.0, 500.0, 468.0, 500.0, 412.0, 500.0, 500.0, 500.0, 500.0, 500.0, 427.0, 500.0, 500.0, 500.0, 500.0, 404.0, 500.0], 'episode_lengths': [79, 59, 30, 99, 226, 171, 131, 256, 184, 77, 152, 180, 94, 136, 54, 227, 232, 167, 85, 153, 195, 162, 167, 120, 172, 295, 154, 203, 324, 91, 250, 57, 64, 103, 286, 275, 233, 166, 139, 267, 340, 178, 237, 99, 357, 206, 66, 383, 389, 288, 261, 388, 322, 202, 332, 310, 188, 348, 221, 86, 99, 291, 302, 500, 369, 492, 367, 249, 363, 279, 203, 324, 122, 500, 500, 324, 296, 460, 500, 500, 359, 418, 348, 294, 500, 468, 500, 412, 500, 500, 500, 500, 500, 427, 500, 500, 500, 500, 404, 500], 'policy_default_policy_reward': [79.0, 59.0, 30.0, 99.0, 226.0, 171.0, 131.0, 256.0, 184.0, 77.0, 152.0, 180.0, 94.0, 136.0, 54.0, 227.0, 232.0, 167.0, 85.0, 153.0, 195.0, 162.0, 167.0, 120.0, 172.0, 295.0, 154.0, 203.0, 324.0, 91.0, 250.0, 57.0, 64.0, 103.0, 286.0, 275.0, 233.0, 166.0, 139.0, 267.0, 340.0, 178.0, 237.0, 99.0, 357.0, 206.0, 66.0, 383.0, 389.0, 288.0, 261.0, 388.0, 322.0, 202.0, 332.0, 310.0, 188.0, 348.0, 221.0, 86.0, 99.0, 291.0, 302.0, 500.0, 369.0, 492.0, 367.0, 249.0, 363.0, 279.0, 203.0, 324.0, 122.0, 500.0, 500.0, 324.0, 296.0, 460.0, 500.0, 500.0, 359.0, 418.0, 348.0, 294.0, 500.0, 468.0, 500.0, 412.0, 500.0, 500.0, 500.0, 500.0, 500.0, 427.0, 500.0, 500.0, 500.0, 500.0, 404.0, 500.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.19439578188943432), 'mean_inference_ms': np.float64(0.6707228199427331), 'mean_action_processing_ms': np.float64(0.07895767599599109), 'mean_env_wait_ms': np.float64(0.04029074512553687), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0043277740478515625), 'StateBufferConnector_ms': np.float64(0.003129243850708008), 'ViewRequirementAgentConnector_ms': np.float64(0.08161735534667969)}, 'num_episodes': 8, 'episode_return_max': 500.0, 'episode_return_min': 30.0, 'episode_return_mean': np.float64(278.86), 'episodes_this_iter': 8}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 427.5975669789947, 'num_env_steps_trained_throughput_per_sec': 427.5975669789947, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 40000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 9385.326, 'restore_workers_time_ms': 0.017, 'training_step_time_ms': 9385.279, 'sample_time_ms': 2011.235, 'load_time_ms': 0.323, 'load_throughput': 12378055.187, 'learn_time_ms': 7369.253, 'learn_throughput': 542.796, 'synch_weights_time_ms': 3.983}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'perf': {'cpu_util_percent': np.float64(15.638461538461542), 'ram_util_percent': np.float64(27.600000000000005)}},\n",
      "    path='/home/lasse/ray_minicourse/lesson_2/ray_results/nb_2/ppo_cartpole/PPO_CartPole-v1_cfa8c_00000_0_gamma=0.9950,lr=0.0000_2024-11-30_02-50-10',\n",
      "    filesystem='local',\n",
      "    checkpoint=Checkpoint(filesystem=local, path=/home/lasse/ray_minicourse/lesson_2/ray_results/nb_2/ppo_cartpole/PPO_CartPole-v1_cfa8c_00000_0_gamma=0.9950,lr=0.0000_2024-11-30_02-50-10/checkpoint_000000)\n",
      "  ),\n",
      "  Result(\n",
      "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(0.36532947), 'cur_kl_coeff': np.float64(0.6750000000000002), 'cur_lr': np.float64(0.0029495964113414592), 'total_loss': np.float64(-0.01114009203619614), 'policy_loss': np.float64(-0.01957856527259273), 'vf_loss': np.float64(0.0027076304654568254), 'vf_explained_var': np.float64(0.846721371335368), 'kl': np.float64(0.00849013701074782), 'entropy': np.float64(0.5356226322151), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(128.0), 'num_grad_updates_lifetime': np.float64(8835.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(464.5)}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'env_runners': {'episode_reward_max': 284.0, 'episode_reward_min': 24.0, 'episode_reward_mean': np.float64(83.7), 'episode_len_mean': np.float64(83.7), 'episode_media': {}, 'episodes_timesteps_total': 8370, 'policy_reward_min': {'default_policy': np.float64(24.0)}, 'policy_reward_max': {'default_policy': np.float64(284.0)}, 'policy_reward_mean': {'default_policy': np.float64(83.7)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [118.0, 58.0, 100.0, 53.0, 68.0, 171.0, 103.0, 99.0, 108.0, 92.0, 284.0, 91.0, 87.0, 58.0, 66.0, 77.0, 81.0, 49.0, 62.0, 93.0, 65.0, 37.0, 71.0, 104.0, 62.0, 90.0, 68.0, 86.0, 62.0, 149.0, 24.0, 57.0, 47.0, 87.0, 93.0, 47.0, 47.0, 54.0, 82.0, 59.0, 90.0, 66.0, 53.0, 92.0, 76.0, 58.0, 119.0, 85.0, 53.0, 100.0, 93.0, 60.0, 78.0, 122.0, 88.0, 55.0, 73.0, 26.0, 79.0, 60.0, 75.0, 94.0, 107.0, 36.0, 110.0, 96.0, 116.0, 124.0, 69.0, 100.0, 57.0, 56.0, 125.0, 82.0, 126.0, 146.0, 75.0, 85.0, 118.0, 77.0, 77.0, 69.0, 83.0, 103.0, 90.0, 80.0, 78.0, 88.0, 69.0, 136.0, 91.0, 65.0, 41.0, 148.0, 79.0, 77.0, 87.0, 72.0, 68.0, 60.0], 'episode_lengths': [118, 58, 100, 53, 68, 171, 103, 99, 108, 92, 284, 91, 87, 58, 66, 77, 81, 49, 62, 93, 65, 37, 71, 104, 62, 90, 68, 86, 62, 149, 24, 57, 47, 87, 93, 47, 47, 54, 82, 59, 90, 66, 53, 92, 76, 58, 119, 85, 53, 100, 93, 60, 78, 122, 88, 55, 73, 26, 79, 60, 75, 94, 107, 36, 110, 96, 116, 124, 69, 100, 57, 56, 125, 82, 126, 146, 75, 85, 118, 77, 77, 69, 83, 103, 90, 80, 78, 88, 69, 136, 91, 65, 41, 148, 79, 77, 87, 72, 68, 60], 'policy_default_policy_reward': [118.0, 58.0, 100.0, 53.0, 68.0, 171.0, 103.0, 99.0, 108.0, 92.0, 284.0, 91.0, 87.0, 58.0, 66.0, 77.0, 81.0, 49.0, 62.0, 93.0, 65.0, 37.0, 71.0, 104.0, 62.0, 90.0, 68.0, 86.0, 62.0, 149.0, 24.0, 57.0, 47.0, 87.0, 93.0, 47.0, 47.0, 54.0, 82.0, 59.0, 90.0, 66.0, 53.0, 92.0, 76.0, 58.0, 119.0, 85.0, 53.0, 100.0, 93.0, 60.0, 78.0, 122.0, 88.0, 55.0, 73.0, 26.0, 79.0, 60.0, 75.0, 94.0, 107.0, 36.0, 110.0, 96.0, 116.0, 124.0, 69.0, 100.0, 57.0, 56.0, 125.0, 82.0, 126.0, 146.0, 75.0, 85.0, 118.0, 77.0, 77.0, 69.0, 83.0, 103.0, 90.0, 80.0, 78.0, 88.0, 69.0, 136.0, 91.0, 65.0, 41.0, 148.0, 79.0, 77.0, 87.0, 72.0, 68.0, 60.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.1992350386598566), 'mean_inference_ms': np.float64(0.6674608949034192), 'mean_action_processing_ms': np.float64(0.07855310032530356), 'mean_env_wait_ms': np.float64(0.04027246995109764), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.004766941070556641), 'StateBufferConnector_ms': np.float64(0.003278970718383789), 'ViewRequirementAgentConnector_ms': np.float64(0.0824594497680664)}, 'num_episodes': 46, 'episode_return_max': 284.0, 'episode_return_min': 24.0, 'episode_return_mean': np.float64(83.7), 'episodes_this_iter': 46}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 421.9762247616093, 'num_env_steps_trained_throughput_per_sec': 421.9762247616093, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 40000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 9418.291, 'restore_workers_time_ms': 0.017, 'training_step_time_ms': 9418.243, 'sample_time_ms': 2024.944, 'load_time_ms': 0.342, 'load_throughput': 11695514.814, 'learn_time_ms': 7388.48, 'learn_throughput': 541.383, 'synch_weights_time_ms': 3.987}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'perf': {'cpu_util_percent': np.float64(15.471428571428573), 'ram_util_percent': np.float64(27.264285714285716)}},\n",
      "    path='/home/lasse/ray_minicourse/lesson_2/ray_results/nb_2/ppo_cartpole/PPO_CartPole-v1_cfa8c_00001_1_gamma=0.5000,lr=0.0029_2024-11-30_02-50-10',\n",
      "    filesystem='local',\n",
      "    checkpoint=Checkpoint(filesystem=local, path=/home/lasse/ray_minicourse/lesson_2/ray_results/nb_2/ppo_cartpole/PPO_CartPole-v1_cfa8c_00001_1_gamma=0.5000,lr=0.0029_2024-11-30_02-50-10/checkpoint_000000)\n",
      "  )\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "config = PPOConfig().environment(\"CartPole-v1\")\n",
    "stop = {\n",
    "    \"training_iteration\": 10,\n",
    "}\n",
    "checkpoint_frequency = 0\n",
    "store_results_path = str(Path(\"./ray_results/\").resolve()) + \"/nb_2/\"\n",
    "agent_name = \"ppo_cartpole\"\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space={\n",
    "        **config.to_dict(),\n",
    "        **search_space,\n",
    "    },  # Here we mix the Algo config with the search space\n",
    "    tune_config=tune_config,\n",
    "    run_config=air.RunConfig(\n",
    "        storage_path=store_results_path,\n",
    "        name=agent_name,\n",
    "        stop=stop,\n",
    "        verbose=2,\n",
    "        checkpoint_config=air.CheckpointConfig(\n",
    "            checkpoint_frequency=checkpoint_frequency,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the logs above, you can check that there are two different trials utilizing different learning rate `lr` and discount factor `gamma` values. Confirming that they sampled different configurations based on the defined search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can check the different training reward performances using tensorboard and looking for the metric `episode_reward_mean`. You can observe two different curves (one for each trial) showing the reward performance over the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 516186), started 0:00:11 ago. (Use '!kill 516186' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ee06a3314352cc16\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ee06a3314352cc16\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ray_results/nb_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray_minicourse-PTDOXG61",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
